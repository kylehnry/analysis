{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5e8e585-a333-4243-b096-ce74b2e83e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zw/9vch0yrs50jfl_28l8p1__m80000gn/T/ipykernel_4075/3471039337.py:4: DtypeWarning: Columns (3,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  trip_data = pd.read_csv('bicycle_trip_data.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First date: 2024-02-01 00:00:00\n",
      "Last date: 2024-05-01 00:00:00\n",
      "This step reduced the number of rows from 13514122 to 1896920 (85.96%)\n",
      "In Comparison to the original data we now look at 14.04% of the data.\n",
      "This step reduced the number of rows from 1896920 to 1443245 (23.92%)\n",
      "In Comparison to the original data we now look at 10.68% of the data.\n",
      "Station data saved to 'station_name_and_nbr.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the trip data\n",
    "trip_data = pd.read_csv('bicycle_trip_data.csv')\n",
    "\n",
    "# Initial number of rows\n",
    "num_rows_step0 = trip_data.shape[0]\n",
    "\n",
    "# Convert 'Start date' to datetime\n",
    "trip_data['Start date'] = pd.to_datetime(trip_data['Start date'])\n",
    "\n",
    "# Only consider the last 3 months of the data\n",
    "trip_data = trip_data[trip_data['Start date'] >= trip_data['Start date'].max() - pd.Timedelta('90 days')]\n",
    "num_rows_step1 = trip_data.shape[0]\n",
    "print(f\"First date: {trip_data['Start date'].min()}\")\n",
    "print(f\"Last date: {trip_data['Start date'].max()}\")\n",
    "print(f\"This step reduced the number of rows from {num_rows_step0} to {num_rows_step1} ({1-(num_rows_step1/num_rows_step0):.2%})\")\n",
    "print(f\"In Comparison to the original data we now look at {(num_rows_step1/num_rows_step0):.2%} of the data.\")\n",
    "\n",
    "# Only consider weekdays\n",
    "trip_data['weekday'] = trip_data['Start date'].dt.weekday\n",
    "trip_data = trip_data[trip_data['weekday'] < 5]\n",
    "num_rows_step2 = trip_data.shape[0]\n",
    "print(f\"This step reduced the number of rows from {num_rows_step1} to {num_rows_step2} ({1-(num_rows_step2/num_rows_step1):.2%})\")\n",
    "print(f\"In Comparison to the original data we now look at {(num_rows_step2/num_rows_step0):.2%} of the data.\")\n",
    "\n",
    "# Record the start and end station name and number for the filtered trips\n",
    "station_data = trip_data[['Start station', 'Start station number', 'End station', 'End station number']]\n",
    "\n",
    "# Save the station data to a new CSV file\n",
    "station_data.to_csv('station_name_and_nbr.csv', index=False)\n",
    "print(\"Station data saved to 'station_name_and_nbr.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a3ed7f-6fff-4154-b072-a645b1ac65ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets\n",
    "trip_data = pd.read_csv('cleaned_trip_data.csv')\n",
    "station_data = pd.read_csv('station_name_and_nbr.csv')\n",
    "\n",
    "# Split station data into two separate DataFrames for start and end stations\n",
    "start_station_data = station_data[['Start station', 'Start station number']].drop_duplicates().rename(columns={'Start station': 'Station', 'Start station number': 'Station number'})\n",
    "end_station_data = station_data[['End station', 'End station number']].drop_duplicates().rename(columns={'End station': 'Station', 'End station number': 'Station number'})\n",
    "\n",
    "# Define a function to merge in smaller chunks incrementally\n",
    "def incremental_merge(trip_data, start_station_data, end_station_data, chunk_size=50000):\n",
    "    chunks = []\n",
    "    for start in range(0, len(trip_data), chunk_size):\n",
    "        trip_chunk = trip_data.iloc[start:start + chunk_size]\n",
    "        trip_chunk = pd.merge(trip_chunk, start_station_data, left_on='Start station', right_on='Station', how='left').rename(columns={'Station number': 'Start station number'}).drop(columns=['Station'])\n",
    "        trip_chunk = pd.merge(trip_chunk, end_station_data, left_on='End station', right_on='Station', how='left').rename(columns={'Station number': 'End station number'}).drop(columns=['Station'])\n",
    "        chunks.append(trip_chunk)\n",
    "    return pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "# Perform the incremental merge\n",
    "trip_data_merged = incremental_merge(trip_data, start_station_data, end_station_data)\n",
    "\n",
    "# Save the merged dataset to a CSV file\n",
    "output_file_path = 'complete_data_final.csv'\n",
    "trip_data_merged.to_csv(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aee8d8-91c3-4f5c-aecf-de657ac3a30f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
